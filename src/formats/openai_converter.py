"""
OpenAIæ ¼å¼è½¬æ¢å™¨
å¤„ç†OpenAI APIæ ¼å¼ä¸å…¶ä»–æ ¼å¼ä¹‹é—´çš„è½¬æ¢
"""
from typing import Dict, Any, Optional, List
import json
import copy

from .base_converter import BaseConverter, ConversionResult, ConversionError


class OpenAIConverter(BaseConverter):
    """OpenAIæ ¼å¼è½¬æ¢å™¨"""
    
    def __init__(self):
        super().__init__()
        self.original_model = None
    
    def set_original_model(self, model: str):
        """è®¾ç½®åŸå§‹æ¨¡å‹åç§°"""
        self.original_model = model
    
    def reset_streaming_state(self):
        """é‡ç½®æ‰€æœ‰æµå¼ç›¸å…³çš„çŠ¶æ€å˜é‡ï¼Œé¿å…çŠ¶æ€æ±¡æŸ“"""
        streaming_attrs = ['_anthropic_stream_id', '_openai_sent_start', '_openai_text_started']
        for attr in streaming_attrs:
            if hasattr(self, attr):
                delattr(self, attr)
    
    def get_supported_formats(self) -> List[str]:
        """è·å–æ”¯æŒçš„æ ¼å¼åˆ—è¡¨"""
        return ["openai", "anthropic", "gemini"]
    
    def convert_request(
        self,
        data: Dict[str, Any],
        target_format: str,
        headers: Optional[Dict[str, str]] = None
    ) -> ConversionResult:
        """è½¬æ¢OpenAIè¯·æ±‚åˆ°ç›®æ ‡æ ¼å¼"""
        try:
            if target_format == "openai":
                # OpenAIåˆ°OpenAIï¼Œæ ¼å¼ä¸æ¸ é“ç›¸åŒï¼Œä¸éœ€è¦è½¬æ¢æ€è€ƒå‚æ•°
                return ConversionResult(success=True, data=data)
            elif target_format == "anthropic":
                return self._convert_to_anthropic_request(data)
            elif target_format == "gemini":
                return self._convert_to_gemini_request(data)
            else:
                return ConversionResult(
                    success=False,
                    error=f"Unsupported target format: {target_format}"
                )
        except Exception as e:
            self.logger.error(f"Failed to convert OpenAI request to {target_format}: {e}")
            return ConversionResult(success=False, error=str(e))
    
    def convert_response(
        self,
        data: Dict[str, Any],
        source_format: str,
        target_format: str
    ) -> ConversionResult:
        """è½¬æ¢å“åº”åˆ°OpenAIæ ¼å¼"""
        try:
            if source_format == "openai":
                return ConversionResult(success=True, data=data)
            elif source_format == "anthropic":
                return self._convert_from_anthropic_response(data)
            elif source_format == "gemini":
                return self._convert_from_gemini_response(data)
            else:
                return ConversionResult(
                    success=False,
                    error=f"Unsupported source format: {source_format}"
                )
        except Exception as e:
            self.logger.error(f"Failed to convert {source_format} response to OpenAI: {e}")
            return ConversionResult(success=False, error=str(e))
    
    def _convert_to_anthropic_request(self, data: Dict[str, Any]) -> ConversionResult:
        """è½¬æ¢OpenAIè¯·æ±‚åˆ°Anthropicæ ¼å¼"""
        result_data = {}
        
        # å¤„ç†æ¨¡å‹ - Anthropic è¦æ±‚å¿…é¡»æœ‰ modelï¼Œä¸åšæ˜ å°„ç›´æ¥ä¼ é€’
        if "model" not in data:
            raise ConversionError("model parameter is required for Anthropic API")
        result_data["model"] = data["model"]
        
        # å¤„ç†æ¶ˆæ¯å’Œç³»ç»Ÿæ¶ˆæ¯
        if "messages" in data:
            system_message, filtered_messages = self._extract_system_message(data["messages"])
            
            if system_message:
                result_data["system"] = system_message
            
            # è½¬æ¢æ¶ˆæ¯æ ¼å¼
            anthropic_messages = []
            for msg in filtered_messages:
                role = msg.get("role")
                
                if role == "user":
                    # ç”¨æˆ·æ¶ˆæ¯ï¼Œæ­£å¸¸è½¬æ¢å†…å®¹
                    anthropic_messages.append({
                        "role": "user",
                        "content": self._convert_content_to_anthropic(msg.get("content", ""))
                    })
                    
                elif role == "assistant":
                    # åŠ©æ‰‹æ¶ˆæ¯ï¼Œæ£€æŸ¥æ˜¯å¦åŒ…å«tool_calls
                    if msg.get("tool_calls"):
                        # è½¬æ¢tool_callsä¸ºtool_use content blocks
                        content_blocks = []
                        for tc in msg["tool_calls"]:
                            if tc and tc.get("type") == "function" and "function" in tc:
                                func = tc["function"]
                                # è§£æarguments JSONå­—ç¬¦ä¸²
                                args_str = func.get("arguments", "{}")
                                try:
                                    args_obj = json.loads(args_str) if args_str else {}
                                except json.JSONDecodeError:
                                    args_obj = {}
                                
                                content_blocks.append({
                                    "type": "tool_use",
                                    "id": tc.get("id", ""),
                                    "name": func.get("name", ""),
                                    "input": args_obj
                                })
                        
                        anthropic_messages.append({
                            "role": "assistant",
                            "content": content_blocks
                        })
                    else:
                        # æ™®é€šåŠ©æ‰‹æ¶ˆæ¯
                        anthropic_messages.append({
                            "role": "assistant",
                            "content": self._convert_content_to_anthropic(msg.get("content", ""))
                        })
                        
                elif role == "tool":
                    # å·¥å…·æ¶ˆæ¯ï¼Œè½¬æ¢ä¸ºç”¨æˆ·æ¶ˆæ¯ä¸­çš„tool_result
                    tool_call_id = msg.get("tool_call_id", "")
                    content = str(msg.get("content", ""))
                    
                    anthropic_messages.append({
                        "role": "user",
                        "content": [
                            {
                                "type": "tool_result",
                                "tool_use_id": tool_call_id,
                                "content": content
                            }
                        ]
                    })
            
            result_data["messages"] = anthropic_messages
        
        # å¤„ç†å…¶ä»–å‚æ•°
        # Anthropic è¦æ±‚å¿…é¡»æœ‰ max_tokensï¼ŒæŒ‰ä¼˜å…ˆçº§å¤„ç†ï¼š
        # 1. ä¼ å…¥çš„max_tokensï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰
        # 2. ç¯å¢ƒå˜é‡ANTHROPIC_MAX_TOKENS
        # 3. éƒ½æ²¡æœ‰åˆ™æŠ¥é”™
        if "max_tokens" in data:
            # ä¼˜å…ˆçº§1ï¼šä½¿ç”¨ä¼ å…¥çš„max_tokens
            result_data["max_tokens"] = data["max_tokens"]
        else:
            # ä¼˜å…ˆçº§2ï¼šæ£€æŸ¥ç¯å¢ƒå˜é‡ANTHROPIC_MAX_TOKENS
            import os
            env_max_tokens = os.environ.get("ANTHROPIC_MAX_TOKENS")
            if env_max_tokens:
                try:
                    max_tokens = int(env_max_tokens)
                    self.logger.info(f"Using ANTHROPIC_MAX_TOKENS from environment: {max_tokens}")
                    result_data["max_tokens"] = max_tokens
                except ValueError:
                    self.logger.warning(f"Invalid ANTHROPIC_MAX_TOKENS value '{env_max_tokens}', must be integer")
                    env_max_tokens = None
            
            if not env_max_tokens:
                # ä¼˜å…ˆçº§3ï¼šéƒ½æ²¡æœ‰åˆ™æŠ¥é”™ï¼Œè¦æ±‚ç”¨æˆ·æ˜ç¡®æŒ‡å®š
                raise ValueError(f"max_tokens is required for Anthropic API. Please specify max_tokens in the request or set ANTHROPIC_MAX_TOKENS environment variable.")
        
        if "temperature" in data:
            result_data["temperature"] = data["temperature"]
        if "top_p" in data:
            result_data["top_p"] = data["top_p"]
        if "stop" in data:
            result_data["stop_sequences"] = data["stop"] if isinstance(data["stop"], list) else [data["stop"]]
        if "stream" in data:
            result_data["stream"] = data["stream"]
        
        # å¤„ç†å·¥å…·è°ƒç”¨
        if "tools" in data:
            anthropic_tools = []
            for tool in data["tools"]:
                if tool.get("type") == "function" and "function" in tool:
                    func = tool["function"]
                    anthropic_tools.append({
                        "name": func.get("name", ""),
                        "description": func.get("description", ""),
                        "input_schema": func.get("parameters", {})
                    })
            result_data["tools"] = anthropic_tools
        
        # å¤„ç†æ€è€ƒé¢„ç®—è½¬æ¢ (OpenAI max_completion_tokens + reasoning_effort -> Anthropic thinkingBudget)
        # é€šè¿‡max_completion_tokensåˆ¤æ–­æ˜¯å¦ä¸ºæ€è€ƒæ¨¡å¼
        if "max_completion_tokens" in data:
            self.logger.info(f"ğŸ§  [THINKING BUDGET] æ£€æµ‹åˆ°OpenAI max_completion_tokenså‚æ•°ï¼Œå¯ç”¨æ€è€ƒæ¨¡å¼")
            
            # ç¡®å®šreasoning_effortï¼šå¦‚æœæ²¡ä¼ åˆ™é»˜è®¤ä¸ºmedium
            reasoning_effort = data.get("reasoning_effort", "medium")
            if "reasoning_effort" not in data:
                self.logger.info(f"ğŸ§  [THINKING BUDGET] æœªæŒ‡å®šreasoning_effortï¼Œé»˜è®¤è®¾ä¸º: '{reasoning_effort}'")
            else:
                self.logger.info(f"ğŸ§  [THINKING BUDGET] ä½¿ç”¨æŒ‡å®šçš„reasoning_effortå‚æ•°: '{reasoning_effort}'")
            
            # æ ¹æ®ç¯å¢ƒå˜é‡æ˜ å°„reasoning_effortåˆ°å…·ä½“çš„tokenæ•°å€¼
            import os
            thinking_budget = None
            env_key = None
            
            if reasoning_effort == "low":
                env_key = "OPENAI_LOW_TO_ANTHROPIC_TOKENS"
                env_value = os.environ.get(env_key)
            elif reasoning_effort == "medium":
                env_key = "OPENAI_MEDIUM_TO_ANTHROPIC_TOKENS"
                env_value = os.environ.get(env_key)
            elif reasoning_effort == "high":
                env_key = "OPENAI_HIGH_TO_ANTHROPIC_TOKENS"
                env_value = os.environ.get(env_key)
            
            self.logger.info(f"ğŸ” [THINKING BUDGET] æŸ¥æ‰¾ç¯å¢ƒå˜é‡: {env_key}")
            
            if not env_value:
                self.logger.error(f"âŒ [THINKING BUDGET] ç¯å¢ƒå˜é‡æœªé…ç½®: {env_key}")
                raise ConversionError(f"ç¯å¢ƒå˜é‡ {env_key} æœªé…ç½®ã€‚è¯·åœ¨.envæ–‡ä»¶ä¸­è®¾ç½®è¯¥å‚æ•°ä»¥æ”¯æŒOpenAI reasoning_effortåˆ°Anthropic thinkingBudgetçš„è½¬æ¢ã€‚")
            
            self.logger.info(f"âœ… [THINKING BUDGET] ç¯å¢ƒå˜é‡è·å–æˆåŠŸ: {env_key} = {env_value}")
            
            try:
                thinking_budget = int(env_value)
                self.logger.info(f"âœ… [THINKING BUDGET] tokenæ•°å€¼è§£ææˆåŠŸ: {thinking_budget}")
            except ValueError:
                self.logger.error(f"âŒ [THINKING BUDGET] tokenæ•°å€¼è§£æå¤±è´¥: '{env_value}' ä¸æ˜¯æœ‰æ•ˆæ•´æ•°")
                raise ConversionError(f"ç¯å¢ƒå˜é‡ {env_key} çš„å€¼ '{env_value}' ä¸æ˜¯æœ‰æ•ˆçš„æ•´æ•°ã€‚")
            
            if thinking_budget:
                result_data["thinking"] = {
                    "type": "enabled",
                    "budget_tokens": thinking_budget
                }
                self.logger.info(f"ğŸ¯ [THINKING BUDGET] è½¬æ¢å®Œæˆ: OpenAI reasoning_effort '{reasoning_effort}' -> Anthropic thinkingBudget {thinking_budget}")
                self.logger.info(f"ğŸ“¤ [THINKING BUDGET] Anthropicè¯·æ±‚å°†åŒ…å«: {{\"thinking\": {{\"type\": \"enabled\", \"budget_tokens\": {thinking_budget}}}}}")
        
        return ConversionResult(success=True, data=result_data)
    
    def _convert_to_gemini_request(self, data: Dict[str, Any]) -> ConversionResult:
        """è½¬æ¢OpenAIè¯·æ±‚åˆ°Geminiæ ¼å¼"""
        result_data = {}
        # é€ä¼ æ¨¡å‹å­—æ®µï¼Œä¿æŒåŸæ ·ä¼ é€’ç»™ Gemini
        if "model" in data:
            result_data["model"] = data["model"]

        def _sanitize_schema(schema: Dict[str, Any]) -> Dict[str, Any]:
            """é€’å½’ç§»é™¤Geminiä¸æ”¯æŒçš„JSON Schemaå…³é”®å­—"""
            if not isinstance(schema, dict):
                return schema

            allowed_keys = {"type", "description", "properties", "required", "enum", "items"}
            sanitized = {k: v for k, v in schema.items() if k in allowed_keys}

            # é€’å½’å¤„ç†å­å±æ€§
            if "properties" in sanitized and isinstance(sanitized["properties"], dict):
                sanitized["properties"] = {
                    prop_name: _sanitize_schema(prop_schema)
                    for prop_name, prop_schema in sanitized["properties"].items()
                }

            # å¤„ç† items
            if "items" in sanitized:
                sanitized["items"] = _sanitize_schema(sanitized["items"])

            return sanitized
        
        # å¤„ç†æ¶ˆæ¯å’Œç³»ç»Ÿæ¶ˆæ¯
        if "messages" in data:
            system_message, filtered_messages = self._extract_system_message(data["messages"])
            
            if system_message:
                # ç¡®ä¿ç³»ç»ŸæŒ‡ä»¤æ ¼å¼æ­£ç¡®
                system_content = str(system_message).strip() if system_message else ""
                if system_content:
                    result_data["system_instruction"] = {
                        "parts": [{"text": system_content}]
                    }
            
            # è½¬æ¢æ¶ˆæ¯æ ¼å¼
            gemini_contents = []
            for msg in filtered_messages:
                msg_role = msg.get("role")

                # 1) æ™®é€š user æ¶ˆæ¯
                if msg_role == "user":
                    gemini_contents.append({
                        "role": "user",
                        "parts": self._convert_content_to_gemini(msg.get("content", ""))
                    })

                # 2) assistant å¸¦ tool_callsï¼ˆfunctionCallï¼‰
                elif msg_role == "assistant" and msg.get("tool_calls"):
                    parts = []
                    for tc in msg["tool_calls"]:
                        if tc and "function" in tc:
                            fn_name = tc["function"].get("name")
                            # OpenAI è§„å®š arguments ä¸º JSON å­—ç¬¦ä¸²
                            arg_str = tc["function"].get("arguments", "{}")
                        else:
                            continue
                        try:
                            arg_obj = json.loads(arg_str) if isinstance(arg_str, str) else arg_str
                        except Exception:
                            arg_obj = {}
                        parts.append({
                            "functionCall": {
                                "name": fn_name,
                                "args": arg_obj
                            }
                        })
                    gemini_contents.append({
                        "role": "model",
                        "parts": parts if parts else [{"text": ""}]
                    })

                # 3) tool ç»“æœ -> functionResponse
                elif msg_role == "tool":
                    tool_call_id = msg.get("tool_call_id", "")
                    # ä» call_<name>_<hash> æå– name
                    fn_name = ""
                    if tool_call_id.startswith("call_"):
                        fn_name = "_".join(tool_call_id.split("_")[1:-1])  # ä¿ç•™ä¸­é—´å«ä¸‹åˆ’çº¿çš„å‡½æ•°å
                    response_content = msg.get("content")
                    # Gemini è¦æ±‚ response ä¸ºå¯¹è±¡
                    if not isinstance(response_content, dict):
                        response_content = {"content": response_content}
                    gemini_contents.append({
                        "role": "tool",
                        "parts": [{
                            "functionResponse": {
                                "name": fn_name,
                                "response": response_content
                            }
                        }]
                    })

                # 4) assistant æ™®é€šæ–‡æœ¬
                else:
                    gemini_contents.append({
                        "role": "model",
                        "parts": self._convert_content_to_gemini(msg.get("content", ""))
                    })
            
            result_data["contents"] = gemini_contents
        
        # å¤„ç†ç”Ÿæˆé…ç½®
        generation_config = {}
        if "temperature" in data:
            generation_config["temperature"] = data["temperature"]
        if "top_p" in data:
            generation_config["topP"] = data["top_p"]
        
        # å¤„ç†maxOutputTokensï¼ˆGeminiçš„max_tokensç­‰ä»·å­—æ®µï¼‰
        # ä¼˜å…ˆçº§ï¼šå®¢æˆ·ç«¯max_tokens > ç¯å¢ƒå˜é‡ANTHROPIC_MAX_TOKENS > ä¸è®¾ç½®ï¼ˆè®©Geminiä½¿ç”¨é»˜è®¤å€¼ï¼‰
        if "max_tokens" in data:
            # ä¼˜å…ˆä½¿ç”¨å®¢æˆ·ç«¯ä¼ å…¥çš„max_tokens
            generation_config["maxOutputTokens"] = data["max_tokens"]
        else:
            # å¦‚æœå®¢æˆ·ç«¯æ²¡æœ‰ä¼ max_tokensï¼Œæ£€æŸ¥ç¯å¢ƒå˜é‡ANTHROPIC_MAX_TOKENS
            import os
            env_max_tokens = os.environ.get("ANTHROPIC_MAX_TOKENS")
            if env_max_tokens:
                try:
                    max_tokens = int(env_max_tokens)
                    generation_config["maxOutputTokens"] = max_tokens
                    self.logger.info(f"Using ANTHROPIC_MAX_TOKENS for Gemini maxOutputTokens: {max_tokens}")
                except ValueError:
                    self.logger.warning(f"Invalid ANTHROPIC_MAX_TOKENS value '{env_max_tokens}', must be integer")
                    # ä¸è®¾ç½®maxOutputTokensï¼Œè®©Geminiä½¿ç”¨é»˜è®¤å€¼
        
        if "stop" in data:
            generation_config["stopSequences"] = data["stop"] if isinstance(data["stop"], list) else [data["stop"]]
        
        # Gemini 2.x è¦æ±‚ generationConfig å­—æ®µå§‹ç»ˆå­˜åœ¨ï¼Œå³ä½¿ä¸ºç©ºå¯¹è±¡
        result_data["generationConfig"] = generation_config
        
        # å¤„ç†å·¥å…·è°ƒç”¨
        if "tools" in data:
            function_declarations = []
            for tool in data["tools"]:
                if tool.get("type") == "function" and "function" in tool:
                    func = tool["function"]
                    function_declarations.append({
                        "name": func.get("name", ""),
                        "description": func.get("description", ""),
                        "parameters": _sanitize_schema(func.get("parameters", {}))
                    })
            
            if function_declarations:
                # Geminiå®˜æ–¹è§„èŒƒä½¿ç”¨ camelCase: functionDeclarations
                result_data["tools"] = [{
                    "functionDeclarations": function_declarations
                }]

        # å¤„ç†ç»“æ„åŒ–è¾“å‡ºï¼ˆæ— è®ºæ˜¯å¦åŒ…å«å·¥å…·è°ƒç”¨ï¼‰
        if "response_format" in data and data["response_format"].get("type") == "json_schema":
            generation_config["response_mime_type"] = "application/json"
            if "json_schema" in data["response_format"]:
                generation_config["response_schema"] = data["response_format"]["json_schema"].get("schema", {})
            result_data["generationConfig"] = generation_config
        
        # å¤„ç†æ€è€ƒé¢„ç®—è½¬æ¢ (OpenAI max_completion_tokens + reasoning_effort -> Gemini thinkingBudget)
        # é€šè¿‡max_completion_tokensåˆ¤æ–­æ˜¯å¦ä¸ºæ€è€ƒæ¨¡å¼
        if "max_completion_tokens" in data:
            self.logger.info(f"ğŸ§  [THINKING BUDGET] æ£€æµ‹åˆ°OpenAI max_completion_tokenså‚æ•°ï¼Œå¯ç”¨æ€è€ƒæ¨¡å¼")
            
            # ç¡®å®šreasoning_effortï¼šå¦‚æœæ²¡ä¼ åˆ™é»˜è®¤ä¸ºmedium
            reasoning_effort = data.get("reasoning_effort", "medium")
            if "reasoning_effort" not in data:
                self.logger.info(f"ğŸ§  [THINKING BUDGET] æœªæŒ‡å®šreasoning_effortï¼Œé»˜è®¤è®¾ä¸º: '{reasoning_effort}'")
            else:
                self.logger.info(f"ğŸ§  [THINKING BUDGET] ä½¿ç”¨æŒ‡å®šçš„reasoning_effortå‚æ•°: '{reasoning_effort}'")
            
            # æ ¹æ®ç¯å¢ƒå˜é‡æ˜ å°„reasoning_effortåˆ°å…·ä½“çš„tokenæ•°å€¼
            import os
            thinking_budget = None
            env_key = None
            
            if reasoning_effort == "low":
                env_key = "OPENAI_LOW_TO_GEMINI_TOKENS"
                env_value = os.environ.get(env_key)
            elif reasoning_effort == "medium":
                env_key = "OPENAI_MEDIUM_TO_GEMINI_TOKENS"
                env_value = os.environ.get(env_key)
            elif reasoning_effort == "high":
                env_key = "OPENAI_HIGH_TO_GEMINI_TOKENS"
                env_value = os.environ.get(env_key)
            
            self.logger.info(f"ğŸ” [THINKING BUDGET] æŸ¥æ‰¾ç¯å¢ƒå˜é‡: {env_key}")
            
            if not env_value:
                self.logger.error(f"âŒ [THINKING BUDGET] ç¯å¢ƒå˜é‡æœªé…ç½®: {env_key}")
                raise ConversionError(f"ç¯å¢ƒå˜é‡ {env_key} æœªé…ç½®ã€‚è¯·åœ¨.envæ–‡ä»¶ä¸­è®¾ç½®è¯¥å‚æ•°ä»¥æ”¯æŒOpenAI reasoning_effortåˆ°Gemini thinkingBudgetçš„è½¬æ¢ã€‚")
            
            self.logger.info(f"âœ… [THINKING BUDGET] ç¯å¢ƒå˜é‡è·å–æˆåŠŸ: {env_key} = {env_value}")
            
            try:
                thinking_budget = int(env_value)
                self.logger.info(f"âœ… [THINKING BUDGET] tokenæ•°å€¼è§£ææˆåŠŸ: {thinking_budget}")
            except ValueError:
                self.logger.error(f"âŒ [THINKING BUDGET] tokenæ•°å€¼è§£æå¤±è´¥: '{env_value}' ä¸æ˜¯æœ‰æ•ˆæ•´æ•°")
                raise ConversionError(f"ç¯å¢ƒå˜é‡ {env_key} çš„å€¼ '{env_value}' ä¸æ˜¯æœ‰æ•ˆçš„æ•´æ•°ã€‚")
            
            if thinking_budget:
                generation_config["thinkingConfig"] = {
                    "thinkingBudget": thinking_budget
                }
                result_data["generationConfig"] = generation_config
                self.logger.info(f"ğŸ¯ [THINKING BUDGET] è½¬æ¢å®Œæˆ: OpenAI reasoning_effort '{reasoning_effort}' -> Gemini thinkingBudget {thinking_budget}")
                self.logger.info(f"ğŸ“¤ [THINKING BUDGET] Geminiè¯·æ±‚å°†åŒ…å«: {{\"generationConfig\": {{\"thinkingConfig\": {{\"thinkingBudget\": {thinking_budget}}}}}}}")
        
        return ConversionResult(success=True, data=result_data)
    
    def _convert_from_anthropic_response(self, data: Dict[str, Any]) -> ConversionResult:
        """è½¬æ¢Anthropicå“åº”åˆ°OpenAIæ ¼å¼"""
        # å¿…é¡»æœ‰åŸå§‹æ¨¡å‹åç§°ï¼Œå¦åˆ™æŠ¥é”™
        if not self.original_model:
            raise ValueError("Original model name is required for response conversion")
            
        import time
        result_data = {
            "id": f"chatcmpl-{data.get('id', 'anthropic')}",
            "object": "chat.completion",
            "created": int(time.time()),  # ä½¿ç”¨å½“å‰æ—¶é—´æˆ³
            "model": self.original_model,  # ä½¿ç”¨åŸå§‹æ¨¡å‹åç§°
            "choices": [],
            "usage": {}
        }
        
        # å¤„ç†å†…å®¹ã€å·¥å…·è°ƒç”¨å’Œæ€è€ƒå†…å®¹
        content = ""
        tool_calls = []
        thinking_content = ""
        
        if "content" in data and isinstance(data["content"], list):
            for item in data["content"]:
                if item.get("type") == "text":
                    content += item.get("text", "")
                elif item.get("type") == "thinking":
                    # æ”¶é›†thinkingå†…å®¹ï¼ŒOpenAI Chat Completions APIä¸ç›´æ¥æ”¯æŒreasoningæ ¼å¼
                    # æˆ‘ä»¬å°†thinkingå†…å®¹ä½œä¸ºç‰¹æ®Šæ ‡è®°åŒ…å«åœ¨å“åº”ä¸­
                    thinking_text = item.get("thinking", "")
                    if thinking_text.strip():
                        thinking_content += thinking_text
                elif item.get("type") == "tool_use":
                    # è½¬æ¢ Anthropic tool_use ä¸º OpenAI tool_calls
                    tool_calls.append({
                        "id": item.get("id", ""),
                        "type": "function",
                        "function": {
                            "name": item.get("name", ""),
                            "arguments": json.dumps(item.get("input", {}), ensure_ascii=False)
                        }
                    })
        
        # å¦‚æœæœ‰thinkingå†…å®¹ï¼Œå°†å…¶ä½œä¸ºå‰ç¼€æ·»åŠ åˆ°contentä¸­
        # ä½¿ç”¨ç‰¹æ®Šæ ¼å¼æ ‡è®°ï¼Œä¾¿äºå®¢æˆ·ç«¯è¯†åˆ«å’Œå¤„ç†
        if thinking_content.strip():
            content = f"<thinking>\n{thinking_content.strip()}\n</thinking>\n\n{content}"
        
        # æ„å»ºæ¶ˆæ¯ï¼Œæ ¹æ®æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨å†³å®šç»“æ„
        message = {"role": "assistant"}
        
        if tool_calls:
            # æœ‰å·¥å…·è°ƒç”¨æ—¶ï¼Œcontent å¯ä»¥ä¸º Noneï¼ˆOpenAI è§„èŒƒï¼‰
            message["content"] = content if content else None
            message["tool_calls"] = tool_calls
            finish_reason = "tool_calls"
        else:
            # æ²¡æœ‰å·¥å…·è°ƒç”¨æ—¶ï¼Œåªæœ‰æ–‡æœ¬å†…å®¹
            message["content"] = content
            finish_reason = self._map_finish_reason(data.get("stop_reason", ""), "anthropic", "openai")
        
        result_data["choices"] = [{
            "index": 0,
            "message": message,
            "finish_reason": finish_reason
        }]
        
        # å¤„ç†ä½¿ç”¨æƒ…å†µ
        if "usage" in data and data["usage"] is not None:
            usage = data["usage"]
            result_data["usage"] = {
                "prompt_tokens": usage.get("input_tokens", 0),
                "completion_tokens": usage.get("output_tokens", 0),
                "total_tokens": usage.get("input_tokens", 0) + usage.get("output_tokens", 0)
            }
        
        return ConversionResult(success=True, data=result_data)
    
    def _convert_from_gemini_response(self, data: Dict[str, Any]) -> ConversionResult:
        """è½¬æ¢Geminiå“åº”åˆ°OpenAIæ ¼å¼"""
        import time
        import random
        import string
        # ç”Ÿæˆç±»ä¼¼OpenAIçš„IDæ ¼å¼
        random_id = ''.join(random.choices(string.ascii_letters + string.digits, k=29))
        # å¿…é¡»æœ‰åŸå§‹æ¨¡å‹åç§°ï¼Œå¦åˆ™æŠ¥é”™
        if not self.original_model:
            raise ValueError("Original model name is required for response conversion")
            
        result_data = {
            "id": f"chatcmpl-{random_id}",
            "object": "chat.completion",
            "created": int(time.time()),  # ä½¿ç”¨å½“å‰æ—¶é—´æˆ³
            "model": self.original_model,  # å¿…é¡»ä½¿ç”¨åŸå§‹æ¨¡å‹åç§°
            "usage": {},
            "choices": []
        }
        
        # å¤„ç†å€™é€‰ç»“æœ
        if "candidates" in data and data["candidates"] and data["candidates"][0]:
            candidate = data["candidates"][0]

            content_text = ""
            tool_calls = []

            if "content" in candidate and "parts" in candidate["content"]:
                for part in candidate["content"]["parts"]:
                    # æ™®é€šæ–‡æœ¬
                    if "text" in part:
                        content_text += part["text"]
                    # å‡½æ•°è°ƒç”¨
                    elif "functionCall" in part:
                        fc = part["functionCall"]
                        fc_name = fc.get("name", "")
                        fc_args = fc.get("args", {})
                        # ç”Ÿæˆ tool_call idï¼Œéµå¾ª "call_<name>_<hash>" è§„åˆ™
                        random_hash = ''.join(random.choices(string.ascii_lowercase + string.digits, k=8))
                        tool_calls.append({
                            "id": f"call_{fc_name}_{random_hash}",
                            "type": "function",
                            "function": {
                                "name": fc_name,
                                "arguments": json.dumps(fc_args, ensure_ascii=False)
                            }
                        })

            # æ„é€  messageï¼Œæ ¹æ®æ˜¯å¦å­˜åœ¨å·¥å…·è°ƒç”¨å†³å®šç»“æ„
            if tool_calls:
                message_dict = {
                    "role": "assistant",
                    "content": None,
                    "tool_calls": tool_calls
                }
                finish_reason_val = "tool_calls"
            else:
                message_dict = {
                    "role": "assistant",
                    "content": content_text
                }
                finish_reason_val = self._map_finish_reason(candidate.get("finishReason", ""), "gemini", "openai")

            result_data["choices"] = [{
                "message": message_dict,
                "finish_reason": finish_reason_val,
                "index": 0
            }]
        
        # å¤„ç†ä½¿ç”¨æƒ…å†µ
        if "usageMetadata" in data:
            usage = data["usageMetadata"]
            result_data["usage"] = {
                "prompt_tokens": usage.get("promptTokenCount", 0),
                "completion_tokens": usage.get("candidatesTokenCount", 0),
                "total_tokens": usage.get("totalTokenCount", 0)
            }
        
        return ConversionResult(success=True, data=result_data)
    
    def _convert_from_gemini_streaming_chunk(self, data: Dict[str, Any]) -> ConversionResult:
        """è½¬æ¢Geminiæµå¼å“åº”chunkåˆ°OpenAIæ ¼å¼"""
        import time
        import random
        import string
        
        # ç”Ÿæˆä¸€è‡´çš„éšæœºIDï¼ˆåœ¨åŒä¸€æ¬¡å¯¹è¯ä¸­ä¿æŒä¸€è‡´ï¼‰
        if not hasattr(self, '_stream_id'):
            self._stream_id = ''.join(random.choices(string.ascii_letters + string.digits, k=29))
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯å®Œæ•´çš„æµå¼å“åº”ç»“æŸ
        if "candidates" in data and data["candidates"] and data["candidates"][0] and data["candidates"][0].get("finishReason"):
            # è¿™æ˜¯æœ€åçš„chunkï¼ŒåŒ…å«finishReason
            # æå–å†…å®¹ï¼ˆGemini æœ€åä¸€ä¸ª chunk ä»å¯èƒ½å¸¦æ–‡æœ¬æˆ–å·¥å…·è°ƒç”¨ï¼‰
            final_content = ""
            tool_calls = []
            candidate = data["candidates"][0]
            if "content" in candidate and candidate["content"].get("parts"):
                for part in candidate["content"]["parts"]:
                    if "text" in part:
                        final_content += part["text"]
                    elif "functionCall" in part:
                        # å¤„ç†å·¥å…·è°ƒç”¨
                        fc = part["functionCall"]
                        fc_name = fc.get("name", "")
                        fc_args = fc.get("args", {})
                        
                        # ç”Ÿæˆ tool_call id
                        if not hasattr(self, '_tool_call_counter'):
                            self._tool_call_counter = 0
                        self._tool_call_counter += 1
                        
                        tool_calls.append({
                            "id": f"call_{fc_name}_{self._tool_call_counter:04d}",
                            "type": "function",
                            "function": {
                                "name": fc_name,
                                "arguments": json.dumps(fc_args, ensure_ascii=False)
                            }
                        })
            
            if not self.original_model:
                raise ValueError("Model name is required for streaming response")
            
            # æ„å»ºdeltaå†…å®¹
            delta = {}
            if final_content:
                delta["content"] = final_content
            if tool_calls:
                delta["tool_calls"] = tool_calls
            
            # ç¡®å®šfinish_reason - å¦‚æœæœ‰å·¥å…·è°ƒç”¨ï¼Œåº”è¯¥æ˜¯tool_calls
            finish_reason = data["candidates"][0].get("finishReason", "")
            if tool_calls:
                mapped_finish_reason = "tool_calls"
            else:
                mapped_finish_reason = self._map_finish_reason(finish_reason, "gemini", "openai")
            
            result_data = {
                "id": f"chatcmpl-{self._stream_id}",
                "object": "chat.completion.chunk",
                "created": int(time.time()),
                "model": self.original_model,
                "choices": [{
                    "index": 0,
                    "delta": delta,
                    "finish_reason": mapped_finish_reason
                }]
            }
            
            # æ·»åŠ usageä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰
            if "usageMetadata" in data:
                usage = data["usageMetadata"]
                result_data["usage"] = {
                    "prompt_tokens": usage.get("promptTokenCount", 0),
                    "completion_tokens": usage.get("candidatesTokenCount", 0),
                    "total_tokens": usage.get("totalTokenCount", 0)
                }
            
            return ConversionResult(success=True, data=result_data)
            
        # æ£€æŸ¥æ˜¯å¦æœ‰å¢é‡å†…å®¹
        elif "candidates" in data and data["candidates"] and data["candidates"][0]:
            candidate = data["candidates"][0]
            content = ""
            tool_calls = []
            
            if "content" in candidate and "parts" in candidate["content"]:
                for part in candidate["content"]["parts"]:
                    if "text" in part:
                        content += part["text"]
                    elif "functionCall" in part:
                        # å¤„ç†å·¥å…·è°ƒç”¨
                        fc = part["functionCall"]
                        fc_name = fc.get("name", "")
                        fc_args = fc.get("args", {})
                        
                        # ç”Ÿæˆ tool_call id
                        if not hasattr(self, '_tool_call_counter'):
                            self._tool_call_counter = 0
                        self._tool_call_counter += 1
                        
                        tool_calls.append({
                            "id": f"call_{fc_name}_{self._tool_call_counter:04d}",
                            "type": "function",
                            "function": {
                                "name": fc_name,
                                "arguments": json.dumps(fc_args, ensure_ascii=False)
                            }
                        })
            
            # å§‹ç»ˆåˆ›å»ºchunkï¼Œå³ä½¿å†…å®¹ä¸ºç©ºï¼ˆè¿™å¯¹æµå¼å¾ˆé‡è¦ï¼‰
            if not self.original_model:
                raise ValueError("Model name is required for streaming response")
            
            # æ„å»ºdeltaå†…å®¹
            delta = {}
            if content:
                delta["content"] = content
            if tool_calls:
                delta["tool_calls"] = tool_calls
            
            result_data = {
                "id": f"chatcmpl-{self._stream_id}",
                "object": "chat.completion.chunk",
                "created": int(time.time()),
                "model": self.original_model,
                "choices": [{
                    "index": 0,
                    "delta": delta,
                    "finish_reason": None
                }]
            }
            
            return ConversionResult(success=True, data=result_data)
        
        # å¦‚æœæ²¡æœ‰candidatesï¼Œå¯èƒ½æ˜¯å…¶ä»–ç±»å‹çš„æ•°æ®ï¼ˆå¦‚å¼€å¤´çš„metadataï¼‰
        # è¿”å›ç©ºçš„deltaä¿æŒæµå¼è¿æ¥
        if not self.original_model:
            raise ValueError("Model name is required for streaming response")
        
        result_data = {
            "id": f"chatcmpl-{self._stream_id}",
            "object": "chat.completion.chunk", 
            "created": int(time.time()),
            "model": self.original_model,
            "choices": [{
                "index": 0,
                "delta": {},
                "finish_reason": None
            }]
        }
        
        return ConversionResult(success=True, data=result_data)
    
    def _convert_from_anthropic_streaming_chunk(self, data: Dict[str, Any]) -> ConversionResult:
        """è½¬æ¢Anthropicæµå¼å“åº”chunkåˆ°OpenAIæ ¼å¼"""
        import time
        import random
        import string
        
        # ç”Ÿæˆä¸€è‡´çš„éšæœºIDï¼ˆåœ¨åŒä¸€æ¬¡å¯¹è¯ä¸­ä¿æŒä¸€è‡´ï¼‰
        if not hasattr(self, '_stream_id'):
            self._stream_id = ''.join(random.choices(string.ascii_letters + string.digits, k=29))
        
        # å¿…é¡»æœ‰åŸå§‹æ¨¡å‹åç§°
        if not self.original_model:
            raise ValueError("Original model name is required for streaming response conversion")
        
        # Anthropicçš„æµå¼å“åº”æ˜¯SSEæ ¼å¼ï¼Œæˆ‘ä»¬éœ€è¦è§£æSSEäº‹ä»¶
        # å¦‚æœä¼ å…¥çš„dataæ˜¯å­—ç¬¦ä¸²ï¼Œè¯´æ˜æ˜¯å®Œæ•´çš„SSEäº‹ä»¶
        if isinstance(data, str):
            # è§£æSSEäº‹ä»¶
            lines = data.strip().split('\n')
            event_type = None
            event_data = None
            
            for line in lines:
                if line.startswith('event: '):
                    event_type = line[7:]
                elif line.startswith('data: '):
                    import json
                    data_content = line[6:]
                    # æ£€æŸ¥æ˜¯å¦æ˜¯ç»“æŸæ ‡è®°
                    if data_content.strip() == "[DONE]":
                        break
                    try:
                        event_data = json.loads(data_content)
                    except json.JSONDecodeError:
                        continue
            
            if not event_data:
                # å¦‚æœæ²¡æœ‰è§£æåˆ°æ•°æ®ï¼Œè¿”å›ç©ºçš„chunk
                result_data = {
                    "id": f"chatcmpl-{self._stream_id}",
                    "object": "chat.completion.chunk",
                    "created": int(time.time()),
                    "model": self.original_model,
                    "choices": [{
                        "index": 0,
                        "delta": {},
                        "finish_reason": None
                    }]
                }
                return ConversionResult(success=True, data=result_data)
        else:
            # å¦‚æœä¼ å…¥çš„æ˜¯JSONå¯¹è±¡ï¼Œç›´æ¥å¤„ç†
            event_data = data
            # ä¼˜å…ˆä½¿ç”¨_sse_eventå­—æ®µï¼ˆç”±unified_apiæ·»åŠ ï¼‰ï¼Œå¦åˆ™ä½¿ç”¨typeå­—æ®µ
            event_type = event_data.get("_sse_event") or event_data.get("type", "")
        
        result_data = {
            "id": f"chatcmpl-{self._stream_id}",
            "object": "chat.completion.chunk",
            "created": int(time.time()),
            "model": self.original_model,
            "choices": [{
                "index": 0,
                "delta": {},
                "finish_reason": None
            }]
        }
        
        # åˆå§‹åŒ–å·¥å…·è°ƒç”¨çŠ¶æ€è·Ÿè¸ª
        if not hasattr(self, '_anthropic_tool_state'):
            self._anthropic_tool_state = {}
        
        # æ ¹æ®äº‹ä»¶ç±»å‹å¤„ç†
        if event_type == "content_block_start":
            # å†…å®¹å—å¼€å§‹ - æ£€æŸ¥æ˜¯å¦æ˜¯å·¥å…·è°ƒç”¨
            content_block = event_data.get("content_block", {})
            if content_block.get("type") == "tool_use":
                tool_index = event_data.get("index", 0)
                self._anthropic_tool_state[tool_index] = {
                    "id": content_block.get("id", ""),
                    "name": content_block.get("name", ""),
                    "arguments": ""
                }
                
                # è¿”å›å·¥å…·è°ƒç”¨å¼€å§‹çš„chunk
                result_data["choices"][0]["delta"]["tool_calls"] = [{
                    "index": tool_index,
                    "id": content_block.get("id", ""),
                    "type": "function",
                    "function": {
                        "name": content_block.get("name", "")
                    }
                }]
        
        elif event_type == "content_block_delta":
            # å†…å®¹å¢é‡
            delta = event_data.get("delta", {})
            index = event_data.get("index", 0)
            
            if delta.get("type") == "text_delta":
                # æ–‡æœ¬å†…å®¹
                result_data["choices"][0]["delta"]["content"] = delta.get("text", "")
            elif delta.get("type") == "input_json_delta":
                # å·¥å…·è°ƒç”¨å‚æ•°å¢é‡
                if index in self._anthropic_tool_state:
                    partial_json = delta.get("partial_json", "")
                    self._anthropic_tool_state[index]["arguments"] += partial_json
                    
                    result_data["choices"][0]["delta"]["tool_calls"] = [{
                        "index": index,
                        "function": {
                            "arguments": partial_json
                        }
                    }]
        
        elif event_type == "content_block_stop":
            # å†…å®¹å—ç»“æŸ - å¯¹å·¥å…·è°ƒç”¨ä¸éœ€è¦ç‰¹æ®Šå¤„ç†ï¼Œå·²åœ¨deltaä¸­ç´¯ç§¯å®Œæˆ
            pass
        
        elif event_type == "message_delta":
            # æ¶ˆæ¯ç»“æŸ
            delta = event_data.get("delta", {})
            stop_reason = delta.get("stop_reason")
            if stop_reason:
                result_data["choices"][0]["finish_reason"] = self._map_finish_reason(stop_reason, "anthropic", "openai")
        
        elif event_type == "message_stop":
            # æµç»“æŸ - æ¸…ç†çŠ¶æ€
            result_data["choices"][0]["finish_reason"] = "stop"
            if hasattr(self, '_anthropic_tool_state'):
                delattr(self, '_anthropic_tool_state')
        
        # å…¶ä»–äº‹ä»¶ç±»å‹ï¼ˆmessage_startï¼‰è¿”å›ç©ºdelta
        
        return ConversionResult(success=True, data=result_data)
    
    def _convert_content_to_anthropic(self, content: Any) -> Any:
        """è½¬æ¢å†…å®¹åˆ°Anthropicæ ¼å¼"""
        if isinstance(content, str):
            # æ£€æŸ¥æ˜¯å¦åŒ…å«thinkingæ ‡ç­¾
            return self._extract_thinking_from_text(content)
        elif isinstance(content, list):
            # å¤„ç†å¤šæ¨¡æ€å†…å®¹ - åº”ç”¨Anthropicæœ€ä½³å®è·µï¼šå›¾ç‰‡åœ¨æ–‡æœ¬ä¹‹å‰
            text_items = []
            image_items = []
            other_items = []
            
            # 1. é¦–å…ˆåˆ†ç±»æ‰€æœ‰å†…å®¹é¡¹
            for item in content:
                if item.get("type") == "text":
                    text_items.append(item)
                elif item.get("type") == "image_url":
                    image_items.append(item)
                else:
                    other_items.append(item)
            
            anthropic_content = []
            
            # 2. é¦–å…ˆå¤„ç†å›¾ç‰‡ï¼ˆAnthropicæœ€ä½³å®è·µï¼‰
            for item in image_items:
                image_url = item.get("image_url", {}).get("url", "")
                if image_url.startswith("data:"):
                    # å¤„ç†base64å›¾åƒ
                    try:
                        media_type, data_part = image_url.split(";base64,", 1)
                        media_type = media_type.replace("data:", "")
                        anthropic_content.append({
                            "type": "image",
                            "source": {
                                "type": "base64",
                                "media_type": media_type,
                                "data": data_part
                            }
                        })
                        self.logger.info(f"âœ… OpenAI->Anthropic: Image processed FIRST (best practice): {media_type}")
                    except ValueError as e:
                        self.logger.error(f"Failed to parse base64 image URL: {e}")
            
            # 3. ç„¶åå¤„ç†æ–‡æœ¬å†…å®¹
            for item in text_items:
                text_content = item.get("text", "")
                # æ£€æŸ¥æ–‡æœ¬æ˜¯å¦åŒ…å«thinkingæ ‡ç­¾
                extracted = self._extract_thinking_from_text(text_content)
                if isinstance(extracted, list):
                    # æœ‰thinkingå†…å®¹ï¼Œç›´æ¥æ·»åŠ åˆ°contentåˆ—è¡¨
                    anthropic_content.extend(extracted)
                else:
                    # æ™®é€šæ–‡æœ¬
                    anthropic_content.append({
                        "type": "text",
                        "text": extracted
                    })
                self.logger.info(f"âœ… OpenAI->Anthropic: Text processed AFTER image (best practice): {text_content[:30]}...")
            
            # 4. å¤„ç†å…¶ä»–ç±»å‹çš„å†…å®¹
            for item in other_items:
                anthropic_content.append(item)
            
            return anthropic_content
        return content
    
    def _extract_thinking_from_text(self, text: str) -> Any:
        """ä»æ–‡æœ¬ä¸­æå–thinkingå†…å®¹ï¼Œè¿”å›Anthropicæ ¼å¼çš„content blocks"""
        import re
        
        # åŒ¹é… <thinking>...</thinking> æ ‡ç­¾
        thinking_pattern = r'<thinking>\s*(.*?)\s*</thinking>'
        matches = re.finditer(thinking_pattern, text, re.DOTALL)
        
        content_blocks = []
        last_end = 0
        
        for match in matches:
            # æ·»åŠ thinkingæ ‡ç­¾ä¹‹å‰çš„æ–‡æœ¬ï¼ˆå¦‚æœæœ‰ï¼‰
            before_text = text[last_end:match.start()].strip()
            if before_text:
                content_blocks.append({
                    "type": "text",
                    "text": before_text
                })
            
            # æ·»åŠ thinkingå†…å®¹
            thinking_text = match.group(1).strip()
            if thinking_text:
                content_blocks.append({
                    "type": "thinking",
                    "thinking": thinking_text
                })
            
            last_end = match.end()
        
        # æ·»åŠ æœ€åä¸€ä¸ªthinkingæ ‡ç­¾ä¹‹åçš„æ–‡æœ¬ï¼ˆå¦‚æœæœ‰ï¼‰
        after_text = text[last_end:].strip()
        if after_text:
            content_blocks.append({
                "type": "text",
                "text": after_text
            })
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°thinkingæ ‡ç­¾ï¼Œè¿”å›åŸæ–‡æœ¬
        if not content_blocks:
            return text
        
        # å¦‚æœåªæœ‰ä¸€ä¸ªæ–‡æœ¬å—ï¼Œè¿”å›å­—ç¬¦ä¸²
        if len(content_blocks) == 1 and content_blocks[0].get("type") == "text":
            return content_blocks[0]["text"]
        
        return content_blocks
    
    def _convert_content_to_gemini(self, content: Any) -> List[Dict[str, Any]]:
        """è½¬æ¢å†…å®¹åˆ°Geminiæ ¼å¼"""
        if isinstance(content, str):
            return [{"text": content}]
        elif isinstance(content, list):
            # å¤„ç†å¤šæ¨¡æ€å†…å®¹
            gemini_parts = []
            for item in content:
                if item.get("type") == "text":
                    gemini_parts.append({"text": item.get("text", "")})
                elif item.get("type") == "image_url":
                    # è½¬æ¢å›¾åƒæ ¼å¼
                    image_url = item.get("image_url", {}).get("url", "")
                    if image_url.startswith("data:"):
                        # å¤„ç†base64å›¾åƒ
                        media_type, data_part = image_url.split(";base64,")
                        media_type = media_type.replace("data:", "")
                        gemini_parts.append({
                            "inlineData": {
                                "mimeType": media_type,
                                "data": data_part
                            }
                        })
            return gemini_parts
        return [{"text": str(content)}]
    
    def _map_finish_reason(self, reason: str, source_format: str, target_format: str) -> str:
        """æ˜ å°„ç»“æŸåŸå› """
        reason_mappings = {
            "anthropic": {
                "openai": {
                    "end_turn": "stop",
                    "max_tokens": "length",
                    "stop_sequence": "stop",
                    "tool_use": "tool_calls"
                }
            },
            "gemini": {
                "openai": {
                    "STOP": "stop",
                    "MAX_TOKENS": "length",
                    "SAFETY": "content_filter",
                    "RECITATION": "content_filter"
                }
            }
        }
        
        try:
            return reason_mappings[source_format][target_format].get(reason, "stop")
        except KeyError:
            return "stop"